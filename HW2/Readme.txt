Programming problem
Part1: Implemented kernel ridge regression with varying regularization hyperparameters (λ = 0.1, 1, 10, 100), visualizing predictions against true test outputs and reporting root-mean-squared-error (RMSE) for each case. Additionally, applied landmark-based features in ridge regression with λ = 0.1, experimenting with different numbers of landmarks (L = 2, 5, 20, 50, 100), analyzing results through visual plots and RMSE calculations to identify an optimal value for L.
Part2: Implemented K-means clustering on a challenging dataset, exploring both hand-crafted feature transformations and kernelized approaches with randomly chosen landmarks, visually assessing clustering outcomes for insights.
Part3: Utilized PCA and t-SNE dimensionality reduction techniques on a subset of MNIST digits data (10,000 examples), visualizing the two-dimensional projections and color-coding each input based on its class to highlight differences between PCA and t-SNE plots.
